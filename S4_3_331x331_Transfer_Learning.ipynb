{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import S2_0_Loading_Data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.regularizers import L2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import Xception, NASNetLarge\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import S4_0_Helper_Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3257, 331, 331, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = S2_0_Loading_Data.load_data(image_size=(331, 331))\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_Xce = Xception(weights='imagenet', include_top=False, input_shape=(331,331, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.0005\n",
    "for layer in pretrained_Xce.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential()\n",
    "model.add(pretrained_Xce)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_regularizer=L2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 11, 11, 2048)      20861480  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 247808)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               126878208 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,743,275\n",
      "Trainable params: 126,880,771\n",
      "Non-trainable params: 20,862,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='CategoricalCrossentropy',\n",
    "              metrics=METRICS)\n",
    "\n",
    "# view model layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 434s 4s/step - loss: 1.1628 - tp: 2480.0000 - fp: 565.0000 - tn: 5949.0000 - fn: 777.0000 - accuracy: 0.7900 - precision: 0.8144 - recall: 0.7614 - auc: 0.9007 - prc: 0.8331 - val_loss: 0.8166 - val_tp: 728.0000 - val_fp: 79.0000 - val_tn: 1551.0000 - val_fn: 87.0000 - val_accuracy: 0.8945 - val_precision: 0.9021 - val_recall: 0.8933 - val_auc: 0.9633 - val_prc: 0.9373\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='val_prc', mode='max',min_delta = 0.01, verbose=1, patience=10,restore_best_weights=True)\n",
    "\n",
    "model_hist = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    validation_data = (test_x, test_y),\n",
    "    epochs = 1, # increase if you have a good computer\n",
    "    verbose = 1,\n",
    "    callbacks = [callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.894478527607362\n",
      "recall: 0.894478527607362\n",
      "precision: 0.894478527607362\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(\n",
    "    test_x\n",
    ")\n",
    "\n",
    "S4_0_Helper_Functions.getAccuracyMetrics(preds, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_NAS = NASNetLarge(weights='imagenet', include_top=False, input_shape=(331, 331, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.0005\n",
    "for layer in pretrained_NAS.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential()\n",
    "model.add(pretrained_NAS)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_regularizer=L2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " NASNet (Functional)         (None, 11, 11, 4032)      84916818  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 487872)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               249790976 \n",
      "                                                                 \n",
      " activation_260 (Activation)  (None, 512)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      " activation_261 (Activation)  (None, 3)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 334,711,381\n",
      "Trainable params: 249,793,539\n",
      "Non-trainable params: 84,917,842\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='CategoricalCrossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# view model layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1231s 12s/step - loss: 1.9556 - tp: 2903.0000 - fp: 808.0000 - tn: 7336.0000 - fn: 1169.0000 - accuracy: 0.7549 - precision: 0.7823 - recall: 0.7129 - auc: 0.8773 - prc: 0.7972 - val_loss: 1.4859 - val_tp: 667.0000 - val_fp: 133.0000 - val_tn: 1497.0000 - val_fn: 148.0000 - val_accuracy: 0.8245 - val_precision: 0.8338 - val_recall: 0.8184 - val_auc: 0.9397 - val_prc: 0.9044\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='val_prc', mode='max',min_delta = 0.01, verbose=1, patience=10,restore_best_weights=True)\n",
    "\n",
    "model_hist = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    validation_data = (test_x, test_y),\n",
    "    epochs = 1, # increase if you have a good computer\n",
    "    verbose = 1,\n",
    "    callbacks = [callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8245398773006135\n",
      "recall: 0.8245398773006135\n",
      "precision: 0.8245398773006135\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(\n",
    "    test_x\n",
    ")\n",
    "\n",
    "S4_0_Helper_Functions.getAccuracyMetrics(preds, test_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b97f87722be283d127c9677e5f24424f6cc3995624eb5ed09943429763561ca"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
